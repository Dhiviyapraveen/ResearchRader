import dotenv from "dotenv";
import path from "path";
import { fileURLToPath } from "url";
import mongoose from "mongoose";
import connectDB from "./src/config/db.js";
import { runAllScrapers } from "./src/services/scraper/index.js";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Load env
dotenv.config({ path: path.join(__dirname, ".env") });

const verifyIntegration = async () => {
  await connectDB();

  console.log("üîÑ Starting Full Integration Verification...");

  try {
    // Replicate scrapeCron.js logic
    console.log("‚ñ∂Ô∏è Calling runAllScrapers()...");
    const { conferences, opportunities } = await runAllScrapers();

    console.log("‚úÖ runAllScrapers() returned:");
    console.log(
      `   - Conferences: ${
        conferences ? conferences.length : "UNDEFINED"
      } items`
    );
    console.log(
      `   - Opportunities: ${
        opportunities ? opportunities.length : "UNDEFINED"
      } items`
    );

    if (!conferences) {
      console.error(
        "‚ùå CRTICAL ERROR: 'conferences' is undefined. This would crash scrapeCron.js!"
      );
    } else {
      console.log(
        "‚úÖ 'conferences' is valid array. scrapeCron.js should proceed safe."
      );
    }

    if (!opportunities) {
      console.error("‚ùå CRTICAL ERROR: 'opportunities' is undefined.");
    } else {
      console.log("‚úÖ 'opportunities' is valid array.");
    }
  } catch (err) {
    console.error("‚ùå Integration verification failed:", err);
  } finally {
    await mongoose.connection.close();
    console.log("‚úÖ DB Connection closed.");
  }
};

verifyIntegration();
